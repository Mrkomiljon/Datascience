{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJhSbs58DJ6J"
   },
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bU6W3WS_E12l"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nN1UNo6HE23b"
   },
   "outputs": [],
   "source": [
    "SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sLLG-r61E2_M"
   },
   "outputs": [],
   "source": [
    "def set_seeds(seed=1234):\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0uih55opr7ye"
   },
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jiN0KrPr71U",
    "outputId": "e3ee36ff-135a-438f-996b-f592dd9c80f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "cuda = True\n",
    "device = torch.device(\"cuda\" if (\n",
    "    torch.cuda.is_available() and cuda) else \"cpu\")\n",
    "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "if device.type == \"cuda\":\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtKqNioAayCy"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9NfIz_4OPYpG"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "q14QCqKxUS2v",
    "outputId": "c64f6dde-cd92-4a44-e178-2acc8764c9d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>...</th>\n",
       "      <th>TechSupport_Yes</th>\n",
       "      <th>StreamingTV_No_internet_service</th>\n",
       "      <th>StreamingTV_Yes</th>\n",
       "      <th>StreamingMovies_No_internet_service</th>\n",
       "      <th>StreamingMovies_Yes</th>\n",
       "      <th>Contract_One_year</th>\n",
       "      <th>Contract_Two_year</th>\n",
       "      <th>PaymentMethod_Credit_card__automatic_</th>\n",
       "      <th>PaymentMethod_Electronic_check</th>\n",
       "      <th>PaymentMethod_Mailed_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74.65</td>\n",
       "      <td>3090.65</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66.70</td>\n",
       "      <td>1077.05</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.50</td>\n",
       "      <td>1497.90</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50.45</td>\n",
       "      <td>50.45</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44.20</td>\n",
       "      <td>403.35</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  SeniorCitizen  Partner  Dependents  tenure  PhoneService  \\\n",
       "0       0              0        0           0      41             1   \n",
       "1       1              0        1           1      17             1   \n",
       "2       0              0        1           1      58             1   \n",
       "3       1              0        0           0       1             1   \n",
       "4       0              0        0           0       9             1   \n",
       "\n",
       "   PaperlessBilling  MonthlyCharges  TotalCharges  Churn  ...  \\\n",
       "0                 1           74.65       3090.65      0  ...   \n",
       "1                 1           66.70       1077.05      0  ...   \n",
       "2                 1           24.50       1497.90      0  ...   \n",
       "3                 1           50.45         50.45      1  ...   \n",
       "4                 1           44.20        403.35      1  ...   \n",
       "\n",
       "   TechSupport_Yes  StreamingTV_No_internet_service  StreamingTV_Yes  \\\n",
       "0                1                                0                0   \n",
       "1                1                                0                0   \n",
       "2                0                                1                0   \n",
       "3                0                                0                0   \n",
       "4                0                                0                0   \n",
       "\n",
       "   StreamingMovies_No_internet_service  StreamingMovies_Yes  \\\n",
       "0                                    0                    1   \n",
       "1                                    0                    0   \n",
       "2                                    1                    0   \n",
       "3                                    0                    0   \n",
       "4                                    0                    0   \n",
       "\n",
       "   Contract_One_year  Contract_Two_year  \\\n",
       "0                  0                  0   \n",
       "1                  0                  0   \n",
       "2                  1                  0   \n",
       "3                  0                  0   \n",
       "4                  0                  0   \n",
       "\n",
       "   PaymentMethod_Credit_card__automatic_  PaymentMethod_Electronic_check  \\\n",
       "0                                      0                               0   \n",
       "1                                      0                               0   \n",
       "2                                      1                               0   \n",
       "3                                      0                               1   \n",
       "4                                      0                               0   \n",
       "\n",
       "   PaymentMethod_Mailed_check  \n",
       "0                           0  \n",
       "1                           1  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "path = '../processed_churn.csv'\n",
    "df = pd.read_csv(path) # load\n",
    "df = df.sample(frac=1).reset_index(drop=True) # shuffle\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "\n",
    "df['tenure'] = sc.fit_transform(df[['tenure']])\n",
    "df['MonthlyCharges'] = sc.fit_transform(df[['MonthlyCharges']])\n",
    "df['TotalCharges'] = sc.fit_transform(df[['TotalCharges']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQ4uWiGciPBS",
    "outputId": "1a1f02a7-c3ad-4b58-f7fd-de5436aecba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (7043, 30)\n",
      "y:  (7043,)\n"
     ]
    }
   ],
   "source": [
    "# Data shapes\n",
    "X = df.drop('Churn', axis=1).values\n",
    "y = df['Churn'].values\n",
    "print (\"X: \", np.shape(X))\n",
    "print (\"y: \", np.shape(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kEIDV2rWkPA"
   },
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VNHCAonhWpQL"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fXVnk18FsaiO"
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.7\n",
    "VAL_SIZE = 0.15\n",
    "TEST_SIZE = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NSffHAoeQmBM"
   },
   "outputs": [],
   "source": [
    "def train_val_test_split(X, y, train_size):\n",
    "    \"\"\"Split dataset into data splits.\"\"\"\n",
    "    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=TRAIN_SIZE, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.5, stratify=y_)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "COyhVvqLz2Ze",
    "outputId": "94e2efd4-ac84-4bd4-cb06-4414b8991ee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (4930, 30), y_train: (4930,)\n",
      "X_val: (1056, 30), y_val: (1056,)\n",
      "X_test: (1057, 30), y_test: (1057,)\n",
      "Sample point: [0.         0.         1.         1.         0.26388889 1.\n",
      " 0.         0.01890547 0.04256866 0.         0.         0.\n",
      " 1.         1.         0.         1.         0.         1.\n",
      " 0.         1.         0.         1.         0.         1.\n",
      " 0.         0.         1.         0.         0.         1.        ] â†’ 0\n"
     ]
    }
   ],
   "source": [
    "# Create data splits\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
    "    X=X, y=y, train_size=TRAIN_SIZE)\n",
    "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "print (f\"Sample point: {X_train[0]} â†’ {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8P2N42lZKW2"
   },
   "source": [
    "## LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GD8gd34w11IA"
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5bYN5NP1ZK0k"
   },
   "outputs": [],
   "source": [
    "class LabelEncoder(object):\n",
    "    \"\"\"Label encoder for tag labels.\"\"\"\n",
    "    def __init__(self, class_to_index={}):\n",
    "        self.class_to_index = class_to_index\n",
    "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.class_to_index)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
    "\n",
    "    def fit(self, y):\n",
    "        classes = np.unique(y)\n",
    "        for i, class_ in enumerate(classes):\n",
    "            self.class_to_index[class_] = i\n",
    "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "        return self\n",
    "\n",
    "    def encode(self, y):\n",
    "        encoded = np.zeros((len(y)), dtype=int)\n",
    "        for i, item in enumerate(y):\n",
    "            encoded[i] = self.class_to_index[item]\n",
    "        return encoded\n",
    "\n",
    "    def decode(self, y):\n",
    "        classes = []\n",
    "        for i, item in enumerate(y):\n",
    "            classes.append(self.index_to_class[item])\n",
    "        return classes\n",
    "\n",
    "    def save(self, fp):\n",
    "        with open(fp, \"w\") as fp:\n",
    "            contents = {'class_to_index': self.class_to_index}\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, fp):\n",
    "        with open(fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrWsgug6ZGLs",
    "outputId": "95fa1d11-b119-4e38-df90-b1a241382960"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "label_encoder.class_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N8me9sECZZUL",
    "outputId": "bc808c0b-dc3b-4f26-cdfe-d646cbcbd4c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train[0]: 0\n",
      "y_train[0]: 0\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to tokens\n",
    "print (f\"y_train[0]: {y_train[0]}\")\n",
    "y_train = label_encoder.encode(y_train)\n",
    "y_val = label_encoder.encode(y_val)\n",
    "y_test = label_encoder.encode(y_test)\n",
    "print (f\"y_train[0]: {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D3syfG98QSC1",
    "outputId": "1a104a16-fa13-4af8-9d52-1bdcc3bf83b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts: [3622 1308]\n",
      "weights: {0: 0.0002760905577029266, 1: 0.0007645259938837921}\n"
     ]
    }
   ],
   "source": [
    "# Class weights\n",
    "counts = np.bincount(y_train)\n",
    "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
    "print (f\"counts: {counts}\\nweights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwZmG3ZDCDdz"
   },
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPIWpCsmCal3"
   },
   "source": [
    "We're going to place our data into a [`Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) and use a [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) to efficiently create batches for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "UBsI7_0gS8CV"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MPUviMfhS8FG",
    "outputId": "3c3820ee-e08e-47f7-d494-7f34c2f08dc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x296b1dd8730>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed seed for reproducibility\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "fK7laA88Cas1"
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<Dataset(N={len(self)})>\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        y = self.y[index]\n",
    "        return [X, y]\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"Processing on a batch.\"\"\"\n",
    "        # Get inputs\n",
    "        batch = np.array(batch, dtype=object)\n",
    "        X = np.stack(batch[:, 0], axis=0)\n",
    "        y = np.stack(batch[:, 1], axis=0)\n",
    "\n",
    "        # Cast\n",
    "        X = torch.FloatTensor(X.astype(np.float32))\n",
    "        y = torch.LongTensor(y.astype(np.int32))\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,\n",
    "            shuffle=shuffle, drop_last=drop_last, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bb835L2XCavW",
    "outputId": "62625b62-7a14-4e46-e93a-720ea85ca26c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "  Train dataset:<Dataset(N=4930)>\n",
      "  Val dataset: <Dataset(N=1056)>\n",
      "  Test dataset: <Dataset(N=1057)>\n",
      "Sample point:\n",
      "  X: [0.         0.         1.         1.         0.26388889 1.\n",
      " 0.         0.01890547 0.04256866 0.         0.         0.\n",
      " 1.         1.         0.         1.         0.         1.\n",
      " 0.         1.         0.         1.         0.         1.\n",
      " 0.         0.         1.         0.         0.         1.        ]\n",
      "  y: 0\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = Dataset(X=X_train, y=y_train)\n",
    "val_dataset = Dataset(X=X_val, y=y_val)\n",
    "test_dataset = Dataset(X=X_test, y=y_test)\n",
    "print (\"Datasets:\\n\"\n",
    "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\n",
    "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\n",
    "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\n",
    "    \"Sample point:\\n\"\n",
    "    f\"  X: {train_dataset[0][0]}\\n\"\n",
    "    f\"  y: {train_dataset[0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQI7OLYDWvhP",
    "outputId": "a6c2fe3b-fdc2-449b-f746-a4ea466d02f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch:\n",
      "  X: [64, 30]\n",
      "  y: [64]\n",
      "Sample point:\n",
      "  X: tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.2639, 1.0000, 0.0000, 0.0189, 0.0426,\n",
      "        0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000,\n",
      "        0.0000, 0.0000, 1.0000])\n",
      "  y: 0\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_dataloader = train_dataset.create_dataloader(batch_size=batch_size)\n",
    "val_dataloader = val_dataset.create_dataloader(batch_size=batch_size)\n",
    "test_dataloader = test_dataset.create_dataloader(batch_size=batch_size)\n",
    "batch_X, batch_y = next(iter(train_dataloader))\n",
    "print (\"Sample batch:\\n\"\n",
    "    f\"  X: {list(batch_X.size())}\\n\"\n",
    "    f\"  y: {list(batch_y.size())}\\n\"\n",
    "    \"Sample point:\\n\"\n",
    "    f\"  X: {batch_X[0]}\\n\"\n",
    "    f\"  y: {batch_y[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yOIyrd3CbpZ"
   },
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "335nEZlJbcda"
   },
   "outputs": [],
   "source": [
    "# Set CUDA seeds\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED) # multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rE9BJAyxCfe4",
    "outputId": "fca0386a-9558-4ea5-9a52-87251406e858"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "cuda = True\n",
    "device = torch.device(\"cuda\" if (\n",
    "    torch.cuda.is_available() and cuda) else \"cpu\")\n",
    "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "if device.type == \"cuda\":\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NWFcZnMCf6N"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAASSRx5ChMn"
   },
   "source": [
    "Let's initialize the model we'll be using to show the capabilities of training utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "o_89ZatDChRt"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "4KpTkA1_ChUI"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = X_train.shape[1] # 2D\n",
    "HIDDEN_DIM = 100\n",
    "DROPOUT_P = 0.1\n",
    "NUM_CLASSES = len(label_encoder.classes)\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "wKfNogAAChWp"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_p, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout = nn.AlphaDropout(dropout_p)\n",
    "        self.fc5 = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x_in, = inputs\n",
    "        z = F.selu(self.fc1(x_in))\n",
    "        z = F.selu(self.fc2(z))\n",
    "        z = F.selu(self.fc3(z))\n",
    "        z = F.selu(self.fc4(z))\n",
    "        z = self.dropout(z)\n",
    "        z = self.fc5(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HBLos7GmCjim",
    "outputId": "ffc1d334-959d-46fe-95b4-34c1b08de112",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of MLP(\n",
      "  (fc1): Linear(in_features=30, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc4): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (dropout): AlphaDropout(p=0.1, inplace=False)\n",
      "  (fc5): Linear(in_features=100, out_features=2, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = MLP(\n",
    "    input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM, \n",
    "    dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
    "model = model.to(device) # set device\n",
    "print (model.named_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOu2HFo1svkj"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIptNMAAsxP8"
   },
   "source": [
    "Let's put all of this together now to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "8fQCkJkDs5kC"
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "m2dbieqks5mv"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-1\n",
    "NUM_EPOCHS = 500\n",
    "PATIENCE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "0sU9D4-qs5sD"
   },
   "outputs": [],
   "source": [
    "# Define Loss\n",
    "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "SVB9PlTos-iZ"
   },
   "outputs": [],
   "source": [
    "# Define optimizer & scheduler\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE) \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "2O0_Uk1tcE6s"
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, device, loss_fn=None, optimizer=None, scheduler=None):\n",
    "\n",
    "        # Set params\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "    def train_step(self, dataloader):\n",
    "        \"\"\"Train step.\"\"\"\n",
    "        # Set model to train mode\n",
    "        self.model.train()\n",
    "        loss = 0.0\n",
    "\n",
    "        # Iterate over train batches\n",
    "        for i, batch in enumerate(dataloader):\n",
    "\n",
    "            # Step\n",
    "            batch = [item.to(self.device) for item in batch]  # Set device\n",
    "            inputs, targets = batch[:-1], batch[-1]\n",
    "            self.optimizer.zero_grad()  # Reset gradients\n",
    "            z = self.model(inputs)  # Forward pass\n",
    "            J = self.loss_fn(z, targets)  # Define loss\n",
    "            J.backward()  # Backward pass\n",
    "            self.optimizer.step()  # Update weights\n",
    "\n",
    "            # Cumulative Metrics\n",
    "            loss += (J.detach().item() - loss) / (i + 1)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def eval_step(self, dataloader):\n",
    "        \"\"\"Validation or test step.\"\"\"\n",
    "        # Set model to eval mode\n",
    "        self.model.eval()\n",
    "        loss = 0.0\n",
    "        y_trues, y_probs = [], []\n",
    "\n",
    "        # Iterate over val batches\n",
    "        with torch.inference_mode():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "\n",
    "                # Step\n",
    "                batch = [item.to(self.device) for item in batch]  # Set device\n",
    "                inputs, y_true = batch[:-1], batch[-1]\n",
    "                z = self.model(inputs)  # Forward pass\n",
    "                J = self.loss_fn(z, y_true).item()\n",
    "\n",
    "                # Cumulative Metrics\n",
    "                loss += (J - loss) / (i + 1)\n",
    "\n",
    "                # Store outputs\n",
    "                y_prob = F.sigmoid(z).cpu().numpy()\n",
    "                y_probs.extend(y_prob)\n",
    "                y_trues.extend(y_true.cpu().numpy())\n",
    "\n",
    "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
    "\n",
    "    def predict_step(self, dataloader):\n",
    "        \"\"\"Prediction step.\"\"\"\n",
    "        # Set model to eval mode\n",
    "        self.model.eval()\n",
    "        y_probs = []\n",
    "\n",
    "        # Iterate over val batches\n",
    "        with torch.inference_mode():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "\n",
    "                # Forward pass w/ inputs\n",
    "                inputs, targets = batch[:-1], batch[-1]\n",
    "                z = self.model(inputs)\n",
    "\n",
    "                # Store outputs\n",
    "                y_prob = F.softmax(z).cpu().numpy()\n",
    "                y_probs.extend(y_prob)\n",
    "\n",
    "        return np.vstack(y_probs)\n",
    "\n",
    "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
    "        best_val_loss = np.inf\n",
    "        for epoch in range(num_epochs):\n",
    "            # Steps\n",
    "            train_loss = self.train_step(dataloader=train_dataloader)\n",
    "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
    "            self.scheduler.step(val_loss)\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = self.model\n",
    "                _patience = patience  # reset _patience\n",
    "            else:\n",
    "                _patience -= 1\n",
    "            if not _patience:  # 0\n",
    "                print(\"Stopping early!\")\n",
    "                break\n",
    "\n",
    "            # Logging\n",
    "            print(\n",
    "                f\"Epoch: {epoch+1} | \"\n",
    "                f\"train_loss: {train_loss:.5f}, \"\n",
    "                f\"val_loss: {val_loss:.5f}, \"\n",
    "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
    "                f\"_patience: {_patience}\"\n",
    "            )\n",
    "        return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ieWtfxfis5ug"
   },
   "outputs": [],
   "source": [
    "# Trainer module\n",
    "trainer = Trainer(\n",
    "    model=model, device=device, loss_fn=loss_fn, \n",
    "    optimizer=optimizer, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zuOVOqfjsxVH",
    "outputId": "6a0ce5b7-cb34-455f-f781-0f4987ef8003",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 20.31044, val_loss: 0.68700, lr: 1.00E-01, _patience: 50\n",
      "Epoch: 2 | train_loss: 0.63845, val_loss: 0.55642, lr: 1.00E-01, _patience: 50\n",
      "Epoch: 3 | train_loss: 0.58212, val_loss: 0.61291, lr: 1.00E-01, _patience: 49\n",
      "Epoch: 4 | train_loss: 0.59687, val_loss: 0.53653, lr: 1.00E-01, _patience: 50\n",
      "Epoch: 5 | train_loss: 0.60348, val_loss: 0.54040, lr: 1.00E-01, _patience: 49\n",
      "Epoch: 6 | train_loss: 0.63544, val_loss: 0.61451, lr: 1.00E-01, _patience: 48\n",
      "Epoch: 7 | train_loss: 0.64937, val_loss: 0.60846, lr: 1.00E-01, _patience: 47\n",
      "Epoch: 8 | train_loss: 0.61215, val_loss: 0.58630, lr: 1.00E-02, _patience: 46\n",
      "Epoch: 9 | train_loss: 0.55867, val_loss: 0.53751, lr: 1.00E-02, _patience: 45\n",
      "Epoch: 10 | train_loss: 0.56185, val_loss: 0.54140, lr: 1.00E-02, _patience: 44\n",
      "Epoch: 11 | train_loss: 0.55912, val_loss: 0.53611, lr: 1.00E-02, _patience: 50\n",
      "Epoch: 12 | train_loss: 0.55196, val_loss: 0.55058, lr: 1.00E-02, _patience: 49\n",
      "Epoch: 13 | train_loss: 0.56029, val_loss: 0.54528, lr: 1.00E-02, _patience: 48\n",
      "Epoch: 14 | train_loss: 0.55708, val_loss: 0.54942, lr: 1.00E-02, _patience: 47\n",
      "Epoch: 15 | train_loss: 0.54895, val_loss: 0.54325, lr: 1.00E-03, _patience: 46\n",
      "Epoch: 16 | train_loss: 0.54718, val_loss: 0.55729, lr: 1.00E-03, _patience: 45\n",
      "Epoch: 17 | train_loss: 0.55318, val_loss: 0.55647, lr: 1.00E-03, _patience: 44\n",
      "Epoch: 18 | train_loss: 0.54333, val_loss: 0.55862, lr: 1.00E-03, _patience: 43\n",
      "Epoch: 19 | train_loss: 0.53825, val_loss: 0.55918, lr: 1.00E-04, _patience: 42\n",
      "Epoch: 20 | train_loss: 0.54814, val_loss: 0.55655, lr: 1.00E-04, _patience: 41\n",
      "Epoch: 21 | train_loss: 0.55266, val_loss: 0.55612, lr: 1.00E-04, _patience: 40\n",
      "Epoch: 22 | train_loss: 0.53674, val_loss: 0.55636, lr: 1.00E-04, _patience: 39\n",
      "Epoch: 23 | train_loss: 0.54898, val_loss: 0.55654, lr: 1.00E-05, _patience: 38\n",
      "Epoch: 24 | train_loss: 0.54119, val_loss: 0.55656, lr: 1.00E-05, _patience: 37\n",
      "Epoch: 25 | train_loss: 0.53764, val_loss: 0.55647, lr: 1.00E-05, _patience: 36\n",
      "Epoch: 26 | train_loss: 0.53557, val_loss: 0.55645, lr: 1.00E-05, _patience: 35\n",
      "Epoch: 27 | train_loss: 0.55494, val_loss: 0.55631, lr: 1.00E-06, _patience: 34\n",
      "Epoch: 28 | train_loss: 0.53977, val_loss: 0.55628, lr: 1.00E-06, _patience: 33\n",
      "Epoch: 29 | train_loss: 0.54258, val_loss: 0.55627, lr: 1.00E-06, _patience: 32\n",
      "Epoch: 30 | train_loss: 0.53513, val_loss: 0.55626, lr: 1.00E-06, _patience: 31\n",
      "Epoch: 31 | train_loss: 0.53788, val_loss: 0.55626, lr: 1.00E-07, _patience: 30\n",
      "Epoch: 32 | train_loss: 0.54633, val_loss: 0.55626, lr: 1.00E-07, _patience: 29\n",
      "Epoch: 33 | train_loss: 0.54579, val_loss: 0.55626, lr: 1.00E-07, _patience: 28\n",
      "Epoch: 34 | train_loss: 0.55157, val_loss: 0.55626, lr: 1.00E-07, _patience: 27\n",
      "Epoch: 35 | train_loss: 0.54977, val_loss: 0.55625, lr: 1.00E-08, _patience: 26\n",
      "Epoch: 36 | train_loss: 0.53637, val_loss: 0.55625, lr: 1.00E-08, _patience: 25\n",
      "Epoch: 37 | train_loss: 0.54267, val_loss: 0.55625, lr: 1.00E-08, _patience: 24\n",
      "Epoch: 38 | train_loss: 0.53765, val_loss: 0.55625, lr: 1.00E-08, _patience: 23\n",
      "Epoch: 39 | train_loss: 0.54085, val_loss: 0.55625, lr: 1.00E-08, _patience: 22\n",
      "Epoch: 40 | train_loss: 0.54391, val_loss: 0.55625, lr: 1.00E-08, _patience: 21\n",
      "Epoch: 41 | train_loss: 0.54428, val_loss: 0.55625, lr: 1.00E-08, _patience: 20\n",
      "Epoch: 42 | train_loss: 0.53839, val_loss: 0.55625, lr: 1.00E-08, _patience: 19\n",
      "Epoch: 43 | train_loss: 0.54784, val_loss: 0.55625, lr: 1.00E-08, _patience: 18\n",
      "Epoch: 44 | train_loss: 0.54445, val_loss: 0.55625, lr: 1.00E-08, _patience: 17\n",
      "Epoch: 45 | train_loss: 0.54364, val_loss: 0.55625, lr: 1.00E-08, _patience: 16\n",
      "Epoch: 46 | train_loss: 0.54351, val_loss: 0.55625, lr: 1.00E-08, _patience: 15\n",
      "Epoch: 47 | train_loss: 0.55179, val_loss: 0.55625, lr: 1.00E-08, _patience: 14\n",
      "Epoch: 48 | train_loss: 0.55234, val_loss: 0.55625, lr: 1.00E-08, _patience: 13\n",
      "Epoch: 49 | train_loss: 0.54202, val_loss: 0.55625, lr: 1.00E-08, _patience: 12\n",
      "Epoch: 50 | train_loss: 0.54619, val_loss: 0.55625, lr: 1.00E-08, _patience: 11\n",
      "Epoch: 51 | train_loss: 0.54310, val_loss: 0.55625, lr: 1.00E-08, _patience: 10\n",
      "Epoch: 52 | train_loss: 0.54373, val_loss: 0.55625, lr: 1.00E-08, _patience: 9\n",
      "Epoch: 53 | train_loss: 0.53578, val_loss: 0.55625, lr: 1.00E-08, _patience: 8\n",
      "Epoch: 54 | train_loss: 0.54434, val_loss: 0.55625, lr: 1.00E-08, _patience: 7\n",
      "Epoch: 55 | train_loss: 0.54996, val_loss: 0.55625, lr: 1.00E-08, _patience: 6\n",
      "Epoch: 56 | train_loss: 0.54786, val_loss: 0.55625, lr: 1.00E-08, _patience: 5\n",
      "Epoch: 57 | train_loss: 0.54421, val_loss: 0.55625, lr: 1.00E-08, _patience: 4\n",
      "Epoch: 58 | train_loss: 0.53818, val_loss: 0.55625, lr: 1.00E-08, _patience: 3\n",
      "Epoch: 59 | train_loss: 0.54266, val_loss: 0.55625, lr: 1.00E-08, _patience: 2\n",
      "Epoch: 60 | train_loss: 0.53840, val_loss: 0.55625, lr: 1.00E-08, _patience: 1\n",
      "Stopping early!\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "best_model = trainer.train(\n",
    "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnjdSO1lxNq6"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "UOsjjwfMxwUi"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, average_precision_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "WUD_Krp-xrdl"
   },
   "outputs": [],
   "source": [
    "def get_performance(y_true, y_pred, classes):\n",
    "    \"\"\"Per-class performance metrics.\"\"\"\n",
    "    # Performance\n",
    "    performance = {\"overall\": {}, \"class\": {}}\n",
    "\n",
    "    # Overall performance\n",
    "    metrics = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    AUPRC = average_precision_score(y_true, y_pred)\n",
    "    AUROC = roc_auc_score(y_true, y_pred)\n",
    "    ConfMatrix = confusion_matrix(y_true, y_pred) \n",
    "    performance[\"overall\"][\"accuracy\"] = accuracy\n",
    "    performance[\"overall\"][\"precision\"] = metrics[0]\n",
    "    performance[\"overall\"][\"recall\"] = metrics[1]\n",
    "    performance[\"overall\"][\"f1\"] = metrics[2]\n",
    "    performance[\"overall\"][\"AUPRC\"] = AUPRC\n",
    "    performance[\"overall\"][\"AUROC\"] = AUROC\n",
    "#     performance[\"overall\"][\"ConfMatrix\"] = ConfMatrix\n",
    "    performance[\"overall\"][\"num_samples\"] = np.float64(len(y_true))\n",
    "    \n",
    "\n",
    "    # Per-class performance\n",
    "    metrics = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
    "    for i in range(len(classes)):\n",
    "        performance[\"class\"][classes[i]] = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": metrics[0][i],\n",
    "            \"recall\": metrics[1][i],\n",
    "            \"f1\": metrics[2][i],\n",
    "            \"AUPRC\": AUPRC,\n",
    "            \"AUROC\": AUROC,\n",
    "            \"num_samples\": np.float64(metrics[3][i]),\n",
    "        }\n",
    "    \n",
    "    print(f'Confusion Matrix: {ConfMatrix}')\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "m8lXcBh9xPZ0"
   },
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
    "y_pred = np.argmax(y_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9exAxINxPgA",
    "outputId": "aaf5143d-3f0e-4d22-f5e6-20d0afc0ef38",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[666 110]\n",
      " [101 180]]\n",
      "{\n",
      "  \"accuracy\": 0.8003784295175024,\n",
      "  \"precision\": 0.8024869027497133,\n",
      "  \"recall\": 0.8003784295175024,\n",
      "  \"f1\": 0.8013694536094588,\n",
      "  \"AUPRC\": 0.4931482500769433,\n",
      "  \"AUROC\": 0.7494084088491031,\n",
      "  \"num_samples\": 1057.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Determine performance\n",
    "performance = get_performance(\n",
    "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
    "print (json.dumps(performance[\"overall\"], indent=2))\n",
    "# print(performance[\"overall\"])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of 10_Utilities",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
